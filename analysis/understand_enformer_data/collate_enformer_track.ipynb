{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a47b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 15:29:15.460935: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8049860",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFR_DIR = \"/clusterfs/nilah/richard/basenji2/data_pretrained_basenji2/human/tfrecords\"\n",
    "BED_PATH = \"/clusterfs/nilah/richard/basenji2/data_pretrained_basenji2/human/sequences.bed\"\n",
    "SEQUENCE_STATS_PATH = \"/clusterfs/nilah/richard/basenji2/data_pretrained_basenji2/human/statistics.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71a394a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_targets': 5313,\n",
       " 'train_seq': 34021,\n",
       " 'valid_seqs': 2213,\n",
       " 'test_seqs': 1937,\n",
       " 'seq_length': 131072,\n",
       " 'pool_width': 128,\n",
       " 'crop_bp': 8192,\n",
       " 'target_length': 896}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_stats = json.load(open(SEQUENCE_STATS_PATH))\n",
    "seq_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2140d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bed_file(seq_stats: dict) -> pd.DataFrame:\n",
    "    df = pd.read_csv(BED_PATH, sep=\"\\t\", names=[\"chrom\", \"start\", \"end\", \"split\"])\n",
    "    df[\"target_start\"] = df[\"start\"] + seq_stats[\"crop_bp\"]\n",
    "    df[\"target_end\"] = df[\"end\"] - seq_stats[\"crop_bp\"]\n",
    "    assert (df[\"target_end\"] - df[\"target_start\"] == seq_stats[\"target_length\"] * seq_stats[\"pool_width\"]).all()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c73490f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_df = load_bed_file(seq_stats)\n",
    "train_bed_df = bed_df[bed_df[\"split\"] == \"train\"].copy()\n",
    "valid_bed_df = bed_df[bed_df[\"split\"] == \"valid\"].copy()\n",
    "test_bed_df = bed_df[bed_df[\"split\"] == \"test\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b37f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_records(filename):\n",
    "    return tf.data.TFRecordDataset(filename, compression_type='ZLIB')\n",
    "\n",
    "def parse_proto(example_proto):\n",
    "    features = {\n",
    "        \"sequence\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    \n",
    "    parsed_features = tf.io.parse_single_example(example_proto, features)\n",
    "    sequence = tf.io.decode_raw(parsed_features[\"sequence\"], tf.uint8)\n",
    "    targets = tf.io.decode_raw(parsed_features[\"target\"], tf.float16)\n",
    "    return sequence, targets\n",
    "\n",
    "def get_data(split: str, bed_df: pd.DataFrame, seq_stats: dict, track_idx: int = 5110):\n",
    "    # Create dataset\n",
    "    tfr_files = natsorted(glob.glob(os.path.join(TFR_DIR, f\"{split}-0-*.tfr\")))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(tfr_files)\n",
    "    dataset = dataset.flat_map(file_to_records)\n",
    "    dataset = dataset.map(parse_proto)\n",
    "    dataset = dataset.batch(1)\n",
    "    \n",
    "    # Get data\n",
    "    outputs = defaultdict(list)\n",
    "    for seq_idx, (_, targets) in tqdm(enumerate(dataset)):\n",
    "        assert seq_idx <= bed_df.shape[0]\n",
    "        targets = targets.numpy().reshape((seq_stats[\"target_length\"], -1))\n",
    "        targets = targets[:, track_idx].astype(np.float32)\n",
    "        n_bins = targets.size\n",
    "        \n",
    "        row = bed_df.iloc[seq_idx]\n",
    "        starts = np.array([\n",
    "            row[\"target_start\"] + i * seq_stats[\"pool_width\"] for i in range(n_bins)\n",
    "        ])\n",
    "        ends = starts + seq_stats[\"pool_width\"]\n",
    "        \n",
    "        outputs[\"chrom\"].extend([row[\"chrom\"]] * n_bins)\n",
    "        outputs[\"start\"].extend(starts)\n",
    "        outputs[\"end\"].extend(ends)\n",
    "        outputs[\"split\"].extend([row[\"split\"]] * n_bins)\n",
    "        outputs[f\"track_{track_idx}\"].extend(targets)\n",
    "        \n",
    "    output_df = pd.DataFrame(outputs)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf58157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34021it [51:45, 10.96it/s]\n"
     ]
    }
   ],
   "source": [
    "train_output_df = get_data(\"train\", train_bed_df, seq_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f739e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2213it [02:16, 16.26it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_output_df = get_data(\"valid\", valid_bed_df, seq_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ca59d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1937it [02:02, 15.76it/s]\n"
     ]
    }
   ],
   "source": [
    "test_output_df = get_data(\"test\", test_bed_df, seq_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4ffb5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.concat((train_output_df, valid_output_df, test_output_df))\n",
    "output_df.to_csv(f\"track_5110.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
