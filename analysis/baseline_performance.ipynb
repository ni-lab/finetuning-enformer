{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from functools import cache, partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import evaluation_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "GENE_CLASS_PATH = \"../finetuning/data/h5_bins_384_chrom_split/gene_class.csv\"\n",
    "GEUVADIS_COUNTS_PATH = \"../process_geuvadis_data/log_tpm/corrected_log_tpm.annot.csv.gz\"\n",
    "BASELINE_PREDS_PATH = \"../baseline/baseline_enformer.384_bins.rc.csv\"\n",
    "METADATA_PATH = \"/data/yosef3/users/ruchir/pgp_uq/data/E-GEUV-1.sdrf.txt\"\n",
    "PREDIXCAN_PREDS_384_BINS_PATH = \"../predixcan_lite/h5_bins_384_chrom_split/384_bins_no_cv/preds.csv\"\n",
    "PREDIXCAN_PREDS_1MB_PATH = \"../predixcan_lite/h5_bins_384_chrom_split/1Mb_no_cv/preds.csv\"\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_preds(path: str) -> pd.DataFrame:\n",
    "    data = np.load(path)\n",
    "    preds = data[\"preds\"]\n",
    "    genes = data[\"genes\"]\n",
    "    samples = data[\"samples\"]\n",
    "\n",
    "    unique_genes = sorted(np.unique(genes))\n",
    "    unique_samples = sorted(np.unique(samples))\n",
    "    gene_to_idx = {gene: idx for idx, gene in enumerate(unique_genes)}\n",
    "    sample_to_idx = {sample: idx for idx, sample in enumerate(unique_samples)}\n",
    "\n",
    "    preds_mtx = np.full((len(unique_genes), len(unique_samples)), np.nan)\n",
    "    for (pred, gene, sample) in zip(preds, genes, samples):\n",
    "        preds_mtx[gene_to_idx[gene], sample_to_idx[sample]] = pred\n",
    "    return pd.DataFrame(preds_mtx, index=unique_genes, columns=unique_samples)\n",
    "\n",
    "\n",
    "def check_sample_split_consistency(df1: pd.DataFrame, df2: pd.DataFrame):\n",
    "    common_genes = df1.index.intersection(df2.index)\n",
    "    for g in common_genes:\n",
    "        df1_samples = df1.loc[g].dropna().index\n",
    "        df2_samples = df2.loc[g].dropna().index\n",
    "        assert set(df1_samples) == set(\n",
    "            df2_samples\n",
    "        ), f\"Samples for gene {g} are not consistent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predixcan_preds_384_bins_df = pd.read_csv(PREDIXCAN_PREDS_384_BINS_PATH, index_col=0)\n",
    "predixcan_preds_1Mb_bins_df = pd.read_csv(PREDIXCAN_PREDS_1MB_PATH, index_col=0)\n",
    "baseline_preds_df = pd.read_csv(BASELINE_PREDS_PATH, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "geuvadis_counts_df = pd.read_csv(GEUVADIS_COUNTS_PATH, index_col=\"our_gene_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlations(\n",
    "    df1: pd.DataFrame, df2: pd.DataFrame, metric: str = \"pearson\"\n",
    ") -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    For metric == r2_score, df1 should contain the true values and df2 the predictions.\n",
    "    \"\"\"\n",
    "    common_genes = df1.index.intersection(df2.index)\n",
    "    correlations = {}\n",
    "    for g in tqdm(common_genes):\n",
    "        df1_samples = df1.loc[g].dropna().index\n",
    "        df2_samples = df2.loc[g].dropna().index\n",
    "        common_samples = df1_samples.intersection(df2_samples)\n",
    "        assert len(common_samples) == 77 or len(common_samples) == 421\n",
    "        if metric == \"spearman\":\n",
    "            corr, _ = spearmanr(df1.loc[g, common_samples], df2.loc[g, common_samples])\n",
    "        elif metric == \"pearson\":\n",
    "            corr, _ = pearsonr(df1.loc[g, common_samples], df2.loc[g, common_samples])\n",
    "        elif metric == \"r2_score\":\n",
    "            corr = r2_score(df1.loc[g, common_samples], df2.loc[g, common_samples])\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric {metric}\")\n",
    "        correlations[g] = corr if not np.isnan(corr) else 0.0\n",
    "    return correlations\n",
    "\n",
    "\n",
    "def get_mean_class_correlation(\n",
    "    gene_to_corrs: dict[str, float], class_: str, abs_corr: bool = False\n",
    "):\n",
    "    assert class_ in [\"random_split\", \"yri_split\", \"unseen\"]\n",
    "    gene_to_class_map = evaluation_utils.get_gene_to_class_map()\n",
    "\n",
    "    my_corrs = []\n",
    "    for g in gene_to_class_map:\n",
    "        if gene_to_class_map[g] != class_:\n",
    "            continue\n",
    "        corr = gene_to_corrs[g]\n",
    "        if abs_corr:\n",
    "            corr = np.abs(corr)\n",
    "        my_corrs.append(corr)\n",
    "\n",
    "    if class_ == \"random_split\" or class_ == \"yri_split\":\n",
    "        assert len(my_corrs) == 200\n",
    "    else:\n",
    "        assert len(my_corrs) == 100\n",
    "    return np.mean(my_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f502f6f3289a410dabafc483b7a87e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2429071/2940098903.py:17: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = pearsonr(df1.loc[g, common_samples], df2.loc[g, common_samples])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aefc10767e684353bbcfc12f7af6bdec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42186a52c061477c90ba221e068e48a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_pearsons = compute_correlations(geuvadis_counts_df, baseline_preds_df)\n",
    "predixcan_384_bin_pearsons = compute_correlations(\n",
    "    geuvadis_counts_df, predixcan_preds_384_bins_df\n",
    ")\n",
    "predixcan_1Mb_pearsons = compute_correlations(\n",
    "    geuvadis_counts_df, predixcan_preds_1Mb_bins_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline random split mean pearson: 0.055\n",
      "Baseline YRI split mean pearson: 0.025\n",
      "Baseline unseen mean pearson: 0.056\n"
     ]
    }
   ],
   "source": [
    "baseline_random_split_mean_pearson = get_mean_class_correlation(\n",
    "    baseline_pearsons, \"random_split\"\n",
    ")\n",
    "baseline_yri_split_mean_pearson = get_mean_class_correlation(\n",
    "    baseline_pearsons, \"yri_split\"\n",
    ")\n",
    "baseline_unseen_mean_pearson = get_mean_class_correlation(baseline_pearsons, \"unseen\")\n",
    "print(f\"Baseline random split mean pearson: {baseline_random_split_mean_pearson:.4f}\")\n",
    "print(f\"Baseline YRI split mean pearson: {baseline_yri_split_mean_pearson:.4f}\")\n",
    "print(f\"Baseline unseen mean pearson: {baseline_unseen_mean_pearson:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline abs random split mean pearson: 0.147703\n",
      "Baseline abs YRI split mean pearson: 0.130\n",
      "Baseline abs unseen mean pearson: 0.138\n"
     ]
    }
   ],
   "source": [
    "baseline_abs_random_split_mean_pearson = get_mean_class_correlation(\n",
    "    baseline_pearsons, \"random_split\", abs_corr=True\n",
    ")\n",
    "baseline_abs_yri_split_mean_pearson = get_mean_class_correlation(\n",
    "    baseline_pearsons, \"yri_split\", abs_corr=True\n",
    ")\n",
    "baseline_abs_unseen_mean_pearson = get_mean_class_correlation(\n",
    "    baseline_pearsons, \"unseen\", abs_corr=True\n",
    ")\n",
    "print(\n",
    "    f\"Baseline abs random split mean pearson: {baseline_abs_random_split_mean_pearson:.4f}\"\n",
    ")\n",
    "print(f\"Baseline abs YRI split mean pearson: {baseline_abs_yri_split_mean_pearson:.4f}\")\n",
    "print(f\"Baseline abs unseen mean pearson: {baseline_abs_unseen_mean_pearson:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predixcan (384 bins context) random spit mean pearson: 0.2702\n",
      "PrediXcan (384 bins context) YRI split mean pearson : 0.1394\n"
     ]
    }
   ],
   "source": [
    "predixcan_384_bin_random_split_mean_pearson = get_mean_class_correlation(\n",
    "    predixcan_384_bin_pearsons, \"random_split\"\n",
    ")\n",
    "predixcan_384_bin_yri_split_mean_pearson = get_mean_class_correlation(\n",
    "    predixcan_384_bin_pearsons, \"yri_split\"\n",
    ")\n",
    "print(\n",
    "    f\"Predixcan (384 bins context) random spit mean pearson: {predixcan_384_bin_random_split_mean_pearson:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"PrediXcan (384 bins context) YRI split mean pearson : {predixcan_384_bin_yri_split_mean_pearson:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predixcan (1Mb context) random spit mean pearson: 0.2633\n",
      "PrediXcan (1Mb context) YRI split mean pearson : 0.1355\n"
     ]
    }
   ],
   "source": [
    "predixcan_1Mb_random_split_mean_pearson = get_mean_class_correlation(\n",
    "    predixcan_1Mb_pearsons, \"random_split\"\n",
    ")\n",
    "predixcan_1Mb_yri_split_mean_pearson = get_mean_class_correlation(\n",
    "    predixcan_1Mb_pearsons, \"yri_split\"\n",
    ")\n",
    "print(\n",
    "    f\"Predixcan (1Mb context) random spit mean pearson: {predixcan_1Mb_random_split_mean_pearson:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"PrediXcan (1Mb context) YRI split mean pearson : {predixcan_1Mb_yri_split_mean_pearson:.4f}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
